{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"https://tfhub.dev/google/movenet/singlepose/lightning/4\"\n",
    "model = hub.load(model_url)\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/01/02-05-83--1-60-23100700000040-01-0.jpg\"\n",
    "image = tf.io.read_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_landmarks(image_path, model):\n",
    "    \"\"\"\n",
    "    주어진 이미지 경로에서 MovNet 모델을 사용하여 랜드마크를 감지합니다.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): 이미지 파일 경로\n",
    "        model: 로드된 TensorFlow Hub MovNet 모델\n",
    "        \n",
    "    Returns:\n",
    "        landmarks (np.ndarray): 감지된 랜드마크 (17x3 배열, keypoint_id, y, x, score)\n",
    "        image (np.ndarray): 처리된 이미지\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 이미지 파일 읽기\n",
    "        image_data = tf.io.read_file(image_path)\n",
    "        \n",
    "        # 이미지 디코딩\n",
    "        image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "        \n",
    "        # 이미지 크기 조정 (192x192)\n",
    "        input_image = tf.image.resize_with_pad(image, 192, 192)\n",
    "        \n",
    "        # 입력 형식에 맞게 변환 (배치 차원 추가 및 정규화)\n",
    "        input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "        input_image = input_image[tf.newaxis, ...]\n",
    "        \n",
    "        # 모델 추론\n",
    "        results = model(input_image)\n",
    "        \n",
    "        # 결과 추출 (키포인트)\n",
    "        keypoints = results['output_0'].numpy()\n",
    "        keypoints = keypoints[0, 0, :, :]  # 첫 번째 사람의 키포인트\n",
    "        \n",
    "        print(f\"감지된 랜드마크 형태: {keypoints.shape}\")\n",
    "        \n",
    "        return keypoints, image.numpy()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n",
    "        return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감지된 랜드마크 형태: (17, 3)\n"
     ]
    }
   ],
   "source": [
    "a, b = detect_landmarks(path, movenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_landmarks(image, keypoints):\n",
    "    \"\"\"\n",
    "    이미지에 감지된 랜드마크를 시각화합니다.\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): 원본 이미지\n",
    "        keypoints (np.ndarray): MovNet에서 감지한 키포인트 (17x3 배열)\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # 키포인트 연결 정의 (COCO 형식)\n",
    "    connections = [\n",
    "        (0, 1), (0, 2), (1, 3), (2, 4),  # 얼굴\n",
    "        (5, 7), (7, 9), (6, 8), (8, 10),  # 팔\n",
    "        (5, 6), (5, 11), (6, 12),  # 어깨와 엉덩이\n",
    "        (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)  # 다리\n",
    "    ]\n",
    "    \n",
    "    # 키포인트 색상 및 연결 색상\n",
    "    keypoint_color = (0, 255, 0)  # 녹색\n",
    "    connection_color = (255, 0, 0)  # 빨간색\n",
    "    \n",
    "    # 결과 이미지 복사\n",
    "    result_image = image.copy()\n",
    "    \n",
    "    # 키포인트 그리기\n",
    "    for y, x, confidence in keypoints:\n",
    "        if confidence > 0.3:  # 신뢰도 임계값\n",
    "            y_px = int(y * height)\n",
    "            x_px = int(x * width)\n",
    "            cv2.circle(result_image, (x_px, y_px), 5, keypoint_color, -1)\n",
    "    \n",
    "    # 연결선 그리기\n",
    "    for connection in connections:\n",
    "        start_idx, end_idx = connection\n",
    "        start_y, start_x, start_conf = keypoints[start_idx]\n",
    "        end_y, end_x, end_conf = keypoints[end_idx]\n",
    "        \n",
    "        if start_conf > 0.3 and end_conf > 0.3:\n",
    "            start_y_px = int(start_y * height)\n",
    "            start_x_px = int(start_x * width)\n",
    "            end_y_px = int(end_y * height)\n",
    "            end_x_px = int(end_x * width)\n",
    "            \n",
    "            cv2.line(result_image, (start_x_px, start_y_px), (end_x_px, end_y_px), connection_color, 2)\n",
    "    \n",
    "    # 결과 시각화\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title('감지된 포즈 랜드마크')\n",
    "    plt.show()\n",
    "    \n",
    "    return result_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
