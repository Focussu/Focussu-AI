import os, json
import pandas as pd
from concurrent.futures import ProcessPoolExecutor
from tqdm import tqdm
import glob
from pathlib import Path
import time

# ìƒìˆ˜ ì •ì˜
BASE_PATH = '/shared_data/focussu/109.í•™ìŠµíƒœë„_ë°_ì„±í–¥_ê´€ì°°_ë°ì´í„°/3.ê°œë°©ë°ì´í„°/1.ë°ì´í„°/Training'
META_PATH = os.path.join(BASE_PATH, '02.ë¼ë²¨ë§ë°ì´í„°')
OUTPUT_DIR = os.path.join(META_PATH, 'train_meta_with_emotion')  # emotion í¬í•¨ëœ íŒŒì¼ ì €ì¥ ê²½ë¡œ

# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(OUTPUT_DIR, exist_ok=True)

def parse_json_with_emotion(file):
    """
    JSON íŒŒì¼ì—ì„œ ëª¨ë“  í•„ìš”í•œ ì •ë³´ë¥¼ í•œ ë²ˆì— ì¶”ì¶œ (emotion í¬í•¨)
    """
    try:
        if not os.path.exists(file):
            return None
        with open(file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
            return {
                'filename': metadata['ì´ë¯¸ì§€']['filename'],
                'format': metadata['ì´ë¯¸ì§€']['format'],
                'idx': metadata['ì´ë¯¸ì§€']['timeline']['id'],
                'category_id': metadata['ì´ë¯¸ì§€']['category']['id'],
                'emotion': metadata['ì´ë¯¸ì§€']['emotion']  # emotion ì¶”ê°€
            }
    except (json.JSONDecodeError, KeyError, FileNotFoundError) as e:
        print(f"Error processing {file}: {str(e)}")
        return None
    except Exception as e:
        print(f"Unexpected error processing {file}: {str(e)}")
        return None

def process_chunk(chunk):
    """ì²­í¬ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
    return pd.DataFrame([r for r in chunk if r is not None])

def reprocess_with_emotion():
    """
    íš¨ìœ¨ì ì¸ ë°©ì‹: ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì²˜ë¦¬ (emotion í¬í•¨)
    - ê° JSON íŒŒì¼ì„ í•œ ë²ˆë§Œ ì½ìŒ
    - ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
    """
    print("ğŸš€ emotion ì—´ì„ í¬í•¨í•œ ì „ì²´ ì¬ì²˜ë¦¬ ì‹œì‘...")
    start_time = time.time()
    
    # JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    meta_files = glob.glob(os.path.join(META_PATH, '*/*.json'))
    print(f"ì²˜ë¦¬í•  JSON íŒŒì¼ ìˆ˜: {len(meta_files):,}")

    if not meta_files:
        print("âŒ ì²˜ë¦¬í•  JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return

    CHUNK_SIZE = 1000

    with ProcessPoolExecutor() as executor:
        for i in range(0, len(meta_files), CHUNK_SIZE):
            chunk = meta_files[i:i + CHUNK_SIZE]

            results = list(tqdm(
                executor.map(parse_json_with_emotion, chunk),
                total=len(chunk),
                desc=f"ì²˜ë¦¬ ì¤‘ì¸ ì²­í¬ {i//CHUNK_SIZE + 1}/{(len(meta_files) + CHUNK_SIZE - 1)//CHUNK_SIZE}"
            ))

            df_chunk = process_chunk(results)
            
            if not df_chunk.empty:
                # ì €ì¥
                output_path = os.path.join(OUTPUT_DIR, f'part_{i//CHUNK_SIZE:04d}.parquet')
                df_chunk.to_parquet(output_path)
                print(f"âœ… ì²­í¬ {i//CHUNK_SIZE + 1} ì €ì¥ ì™„ë£Œ ({len(df_chunk)} í–‰)")

            # ë©”ëª¨ë¦¬ í•´ì œ
            del df_chunk
            del results

    elapsed_time = time.time() - start_time
    print(f"âœ… ì™„ë£Œ! emotion í¬í•¨ëœ parquet íŒŒì¼ë“¤ì´ ì €ì¥ë¨: {OUTPUT_DIR}")
    print(f"â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ“Š Emotion ì—´ì„ í¬í•¨í•œ ë°ì´í„° ì „ì²˜ë¦¬")
    print("=" * 60)
    print()
    print("ğŸ’¡ ì²˜ë¦¬ ë°©ì‹: JSON íŒŒì¼ì„ í•œ ë²ˆë§Œ ì½ì–´ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬")
    print(f"ğŸ“ ì¶œë ¥ ê²½ë¡œ: {OUTPUT_DIR}")
    print()
    
    reprocess_with_emotion() 